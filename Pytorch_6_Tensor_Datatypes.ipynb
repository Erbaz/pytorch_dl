{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/j7UZeiG1qZic0/0L+fP8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Erbaz/pytorch_dl/blob/main/Pytorch_6_Tensor_Datatypes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tensor Datatypes\n"
      ],
      "metadata": {
        "id": "td_DhZOYnuyD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NqNKO64nr6O",
        "outputId": "d821f9c6-1b5f-49cf-f053-eec7dff52764"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Default datatype of a tensor is float32\n",
        "\n",
        "tensor_default = torch.rand(2, 3, 3)\n",
        "tensor_default.dtype # dtype is a getter to obtain the datatype of the tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a tensor with a diffetent dtype is possible\n",
        "\n",
        "tensor_f16 = torch.tensor([3, 6, 9], dtype=torch.float16 )\n",
        "tensor_f16.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibyDmp8DoXlj",
        "outputId": "f19f4f8d-2c94-46da-a263-73ac0be5804a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float16"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`float32` stores each value using 32 bits. It is referred to as single-precision. \\\n",
        "\n",
        "`float16` stores each value using 16 bits. It is referred to as half-precion\n",
        "\n"
      ],
      "metadata": {
        "id": "B3TfD_rPqKT3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing datatypes\n",
        "tensor_f16_convert = tensor_default.type(torch.float16)\n",
        "\n",
        "tensor_f16_convert"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeTrsoBgteXJ",
        "outputId": "be658cf7-7424-4fa7-956d-f0d1e924083d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.2817, 0.5752, 0.3889],\n",
              "         [0.1065, 0.1301, 0.0754],\n",
              "         [0.2395, 0.2732, 0.7812]],\n",
              "\n",
              "        [[0.0624, 0.6738, 0.2349],\n",
              "         [0.3135, 0.3560, 0.7593],\n",
              "         [0.6636, 0.4866, 0.4473]]], dtype=torch.float16)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Tensor Params\n",
        "1. datatype\n",
        "2. shape\n",
        "3. device\n",
        "\n",
        "Tensors must be of the same datatype to perform operations amongst themselves. Mismatch in datatypes leads to error as precisions cannot be reconciled. \\\n",
        "\n",
        "Tensors need to be of the right shape to operate with other tensors. Such as in masking, you require zeros tensor to be of the same shape as the targeted tensor. \\\n",
        "\n",
        "Tensors need to be on the same device to be computed. If one is on a `cpu` while the other is on a `cuda` then there will be a referrence error."
      ],
      "metadata": {
        "id": "5YGbGILOrBmW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_tensor = torch.tensor([1,2,3], # shape of the tensor. In this case it is 1x1x3\n",
        "                          dtype=None, # defaults to torch.float32\n",
        "                          device=None, # defaults to system device (cpu in this case)\n",
        "                          requires_grad=False # wether or not gradient for tensor needs to be computed\n",
        "                          )\n",
        "new_tensor.shape, new_tensor.dtype, new_tensor.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zn6NNL3NrLYl",
        "outputId": "d427970a-0963-47bb-9584-7617755e8ba8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3]), torch.int64, device(type='cpu'))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}